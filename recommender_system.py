# -*- coding: utf-8 -*-
"""Submission_Recommender_System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X-HJFKW94-nD2wmwR7MF3uQHgJVKchrA

# **Movie Recommeded System**

**Sumber Dataset**: [Movie Lens Small Latest Dataset](https://www.kaggle.com/datasets/shubhammehta21/movie-lens-small-latest-dataset/)

**Deskripsi**: Notebook ini berisi proses pembuatan sistem rekomendasi film

## **Import Library yang Dibutuhkan**
"""

! pip install kaggle

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import os
from google.colab import drive
drive.mount('/content/drive')

"""## **Data Understanding**

Pada bagian ini, data akan dieksplor dengan tujuan untuk memahami isi, kualitas, dan penanganan data pada bagian selanjuetnya.

Dataset yang digunakan dalam proyek kali ini berjudul [Movie Lens Small Latest Dataset](https://www.kaggle.com/datasets/shubhammehta21/movie-lens-small-latest-dataset/). Dataset ini berisi data rating dan free tagging (label bebas yang diberikan user kepada film) dari website [movielens.org](https://movielens.org/), sebuah layanan rekomendasi film. Untuk lebih detilnya, dataset ini berisi 100836 rating dan 3683 data tag di 9742 film. Data ini dibuat oleh 610 pengguna antara 29 Maret 1996 dan 24 September 2018.

Setelah dataset diunduh dan diekstrak, akan didapatkan file sebagai berikut.
- README.txt
- links.csv
- movies.csv
- ratings.csv
- tags.csv

Pada proyek kali ini, file yang akan digunakan meliputi movies.csv dan ratings.csv.

### **Data Loading**

Pada bagian ini, file **movies.csv** dan **ratings.csv** akan dimuat menggunakan library pandas
"""

# Mengatur config kaggle supaya bisa download langsung lewat CLI
os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive/Kaggle'

# Download dataset dari kaggle
! kaggle datasets download shubhammehta21/movie-lens-small-latest-dataset

# Unzip dataset
! unzip /content/movie-lens-small-latest-dataset.zip

"""#### Membaca file movies.csv"""

movies_df = pd.read_csv('/content/movies.csv')
movies_df

"""#### Membaca file ratings.csv"""

ratings_df = pd.read_csv('/content/ratings.csv')
ratings_df

"""**Insight:** Dari pembacaan data di atas, diketahui bahwa jumlah data dalam movies_df adalah 9742 data dengan 3 fitur utama yaitu movieId, title, dan genres. Sedangkan data dalam rating_df berjumlah 100836 data dengan 4 fitur utama, meliputi userId, movieId, rating, dan timestamp

### **Exploratory Data Analysis**

Exploratory Data Analysis merupakan proses investigasi awal pada data untuk menganalisis karakteristik, menemukan pola, anomali, dan memeriksa asumsi pada data. Teknik ini biasanya menggunakan bantuan statistik dan representasi grafis atau visualisasi. Tujuan dari EDA adalah untuk memperoleh wawasan awal yang mendalam mengenai data dan menentukan langkah selanjutnya dalam analisis atau pemodelan.

Pada proyek kali ini, proses yang akan kita lakukan meliputi:
- **Deskripsi Data**
- **Univariate Analysis**  
- **Multivariate Analaysis**

#### **Deskripsi Data**
"""

movies_df.info()

"""movies_df di atas berisi 9742 data film dengan 3 fitur utama, meliputi:
1. movieId (integer) -  Unique ID untuk film, contoh 1, 2, 3, dsb.
2. title (object) - judul film, contoh Toy Story
3. genre (object) - genre film, jika lebih dari satu dipisah dengan '|'. Contohnya Comedy|Romance
"""

movies_df.describe(include='all')

ratings_df.info()

"""rating_df di atas berisi 100836 data rating dengan 4 fitur utama, meliputi:
1. userId (integer) -  Unique ID untuk user, contoh 1, 2, 3, dsb.
2. movieId (integer) - Unique ID untuk film, contoh 1, 2, 3, dsb.
3. rating (float) - nilai/rating film yang diberikan oleh user, dari skala 0.5 - 5.0
4. timestamp (integer) - Waktu rating direkam (format Unix timestamp)
"""

ratings_df.describe(include='all')

"""**Insight**: Dataset yang digunakan dalam proyek ini memiliki dua tipe data utama, yaitu numerikal dan kategorikal. Numerikal meliputi `userId`, `movieId`, `rating`, dan `timestamp`. Kemudian untuk kategorikal meliputi `title` dan `genre`. Fitur rating dalam data di atas memiliki nilai rata-rata sebesar 3.55 dari skala 0.5 hingga 5. Nilai ini menyisyaratkan bahwa rating yang diberikan pengguna rata-rata adalah sedang/lumayan atau bisa juga karena keberagaman rating yang ada dalam data proyek ini.

#### **Univariate Analysis**

Analisis ini merupakan analisis pada tiap fitur dengan tujuan untuk mengetahui karakteristik dan struktur pada variabel
"""

print('Jumlah data film dalam movie_df: ', len(movies_df.movieId.unique()))
print('Jumlah data genre film: ', len(movies_df.genres.unique()))
print('Jumlah data film yang diberi rating dalam rating_df: ', len(ratings_df.movieId.unique()))
print('Jumlah data user yang memberi rating : ', len(ratings_df.userId.unique()))
print('Jumlah data rating yang diberikan: ', len(ratings_df))

"""Terlihat pada output di atas bahwa jumlah film unik pada movies_df dan ratings_df berbeda. Dapat disimpulkan bahwa tidak semua film dalam movies_df sudah diberi rating oleh pengguna"""

print('Genre film: ', movies_df.genres.unique())

"""Terlihat dari output di atas, data genre kebanyakan berisi lebih dari satu tiap datanya. Hal ini normal untuk sebuah film"""

# Melihat genre secara unique atau satuan
def genre_unique():
  genre = []
  for i in movies_df.genres.unique():
    for j in i.split('|'):
      if j not in genre:
        genre.append(j)
  return genre

print('Jumlah genre unik: ', len(genre_unique()))
print('Genre unik: ')
print(*genre_unique(), sep='\n')

"""Dari output di atas, terlihat bahwa ada film yang genrenya tidak dicantumkan atau tidak ditulis dalam data, representasi genrenya ditulis dengan no genre list"""

movies_df[movies_df.genres == '(no genres listed)']

len(movies_df[movies_df.genres == '(no genres listed)'])

"""Terlihat bahwa ada 34 film yang tidak mencantumkan genrenya dalam data. Dan direpresentasikan dengan no genre list

**Cek Nilai Kosong**
"""

movies_df.isnull().sum()

ratings_df.isnull().sum()

"""**Cek Nilai Duplikat**"""

movies_df.duplicated().sum()

ratings_df.duplicated().sum()

"""**Distribusi Data**"""

# 10 userId pemberi rating paling banyak
print(ratings_df.userId.value_counts().sort_values(ascending=False).head(10))
sns.barplot(x=ratings_df.userId.value_counts().sort_values(ascending=False).head(10).index, y=ratings_df.userId.value_counts().sort_values(ascending=False).head(10).values)
plt.show()

rating_count = ratings_df.rating.value_counts().sort_values(ascending=False)
print(rating_count)

sns.barplot(x=rating_count.index, y=rating_count.values)
plt.show()

"""**Insight**:
- Dataset proyek ini memiliki 9742 data film unik. Dengan 20 kategori genre unik, meliputi Action hingga Western. Selain itu, terdapat pula genre '(no genres listed)' yang menunjukkan ada beberapa film yang data genrenya kurang lengkap
- Terdapat 34 data Genre bernilai '(no genres listed)' dalam dataset. Untuk proyek ini, kita akan menggantinya menjadi satu kata untuk mengurangi term saat proses TFIDF nantinya
- Dataset pada proyek ini memiliki 610 data pengguna unik, serta 100836 data rating yang diberikan pada film
- Jumlah data film unik pada movies_df dan ratings_df berbeda. Dapat disimpulkan bahwa tidak semua film dalam movies_df sudah diberi rating oleh pengguna
- Tidak ditemukan adanya nilai kosong dan duplikat pada data, sehingga penanganan tidak diperlukan
- Melalui eksplorasi, ditemukan bahwa pengguna dengan userId 414 merupakan pengguna yang paling banyak memberikan rating pada film (2698 rating), disusur dengan userId 599(2478 rating), serta userId 474 (2108 rating)
- Rating yang diberikan pengguna dalam dataset cukup beragam dari 0.5 hingga 5.0. Rating 4.0 merupakan rating terbanyak yang diberikan pengguna pada film, sedangkan 0.5 adalah rating dengan jumlah paling sedikit yang diberikan pengguna pada film

#### **Multivariate Analysis**

Multivariate analysis adalah jenis analisis statistik atau eksplorasi data yang melibatkan tiga atau lebih variabel secara bersamaan, dengan tujuan untuk Mencari pola, hubungan, atau pengaruh antar variabel
"""

# Top 10 film dengan rating terbaik
df = pd.merge(ratings_df, movies_df, on='movieId', how='left')
best_movies = df.groupby(by='title').agg({
    'rating': 'mean',
    'userId': 'count'
}).sort_values(by=['rating', 'userId'], ascending=False).head(10)
best_movies

# Top 10 paling banyak diberi rating
df = pd.merge(ratings_df, movies_df, on='movieId', how='left')
popular_movies = df.groupby(by='title').agg({
    'rating': 'mean',
    'userId': 'count'
}).sort_values(by=['userId'], ascending=False).head(10)
popular_movies

"""**Insight**:
- Melaui eksplorasi, ditemukan bahwa Belle époque (1992), Come and See (Idi i smotri) (1985), Enter the Void (2009), Heidi Fleiss: Hollywood Madam (1995), Jonah Who Will Be 25 in the Year 2000 (Jonas qui aura 25 ans en l'an 2000) (1976), Lamerica (1994), dan Lesson Faust (1994) merupakan film dengan rating terbaik (5.0) jika diurutkan berdasarkan rating dan jumlah rating. Jumlah rating yang dimiliki oleh film tersebut adalah 2, yang mana sangat sedikit
- Melalui ekplorasi, ditemukan bahwa Forrest Gump (1994) merupakan film yang memiliki jumlah rating terbanyak yang diberikan pengguna (329 rating), disusul oleh Shawshank Redemption, The (1994) (317 rating), dan Pulp Fiction (1994) (307 rating)

### **Data Preparation**

Setelah melalui tahapan Data Understanding dan sebelum membangun model machine learning, diperlukan tahapan data preparation untuk memastikan bahwa data dalam kondisi bersih, konsisten, dan siap untuk digunakan dalam proses pelatihan model. Pada proyek ini akan dilakukan beberapa tahapan, yaitu,
- Menghapus Fitur yang tidak Diperlukan
- Tranformasi nilai fitur genres pada dataset
- Persiapan data model Content Based Filtering
- Persiapan data model Collaborative Filtering

Pada tahapan ini pembersihan data seperti menghapus nilai kosong dan duplikat tidak dilakukan karena tidak ditemukan adanya nilai-nilai tersebut pada data

#### **Menghapus Fitur yang tidak Diperlukan**

Pada proyek kali ini, kita tidak akan menggunakan fitur atau kolom timestamp. Oleh sebab itu, kita akan menghapusnya di sini
"""

ratings_df = ratings_df.drop(columns=['timestamp'])
ratings_df

"""#### **Transformasi Fitur Genres**

Pada bagian ini, format nilai genre akan diubah dengan menghapus `'|'` menjadi `spasi`. Hal ini dilakukan agar nilai dari genres lebih rapi.

Pada bagian ini juga dilakukan pengubahan nilai '(no genres listed)' menjadi satu kata yaitu, '(no_genres_listed)'. Hal ini dilakukan untuk mengurangi matriks term yang dihasilkan oleh proses TFIDF nantinya
"""

movies_df.genres = movies_df.genres.str.replace('|', ' ')
movies_df.genres = movies_df.genres.str.replace('(no genres listed)', '(no_genres_listed)')
movies_df

print(len(movies_df[(movies_df.genres == '(no genres listed)')]))

print(len(movies_df[(movies_df.genres == '(no_genres_listed)')]))

"""Terlihat pada output di atas bahwa nilai `'|'` sudah terganti menjadi spasi dan nilai '(no genres listed)' sudah berubah menjadi satu kata

#### **Persiapan data model Content Based Filtering**

##### **Mengubah genre film menjadi vektor TF-IDF**

Pada tahap ini, kita akan menggunakan fitur genres pada movies_df
"""

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer(token_pattern=r'(?u)\b[\w\-]+\b')

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(movies_df['genres'])

# Melihat ukuran matrix tfidf
print(tfidf_matrix.shape)

# Mapping array dari fitur index integer ke fitur nama
print(tf.get_feature_names_out())

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

# Membuat dataframe untuk melihat tf-idf matrix
pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=movies_df.title
)

"""##### **Menghitung nilai similarity dengan cosine similarity**"""

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama resto
cosine_sim_df = pd.DataFrame(cosine_sim, index=movies_df.title, columns=movies_df.title)
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap resto
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""#### **Persiapan data model Collaborative Filtering**

##### **Penggabungan Data**
"""

rating_movies = pd.merge(ratings_df, movies_df, on='movieId', how='left')
rating_movies.head()

"""##### **Encoding ID Pengguna dan Film**"""

# Mengubah userId menjadi list tanpa nilai yang sama
user_ids = rating_movies['userId'].unique().tolist()
print('list userId: ', user_ids)

# Melakukan encoding userId
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userId : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke userId
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userId: ', user_encoded_to_user)

# Mengubah movieId menjadi list tanpa nilai yang sama
movie_ids = rating_movies['movieId'].unique().tolist()

# Melakukan proses encoding movieId
movie_to_movie_encoded = {x: i for i, x in enumerate(movie_ids)}

# Melakukan proses encoding angka ke movieId
movie_encoded_to_movie = {i: x for i, x in enumerate(movie_ids)}

# Mapping userID ke dataframe user
rating_movies['user'] = rating_movies['userId'].map(user_to_user_encoded)

# Mapping placeID ke dataframe resto
rating_movies['movie'] = rating_movies['movieId'].map(movie_to_movie_encoded)

"""##### **Pengacakan Dataset**"""

# Pengacakan dataset untuk menghindari Bias Urutan Data dan
rating_movies = rating_movies.sample(frac=1, random_state=42)
rating_movies

"""##### **Normalisasi Rating ke dalam rentang 0-1**"""

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)

# Mendapatkan jumlah film
num_movies = len(movie_encoded_to_movie)
print(num_movies)

# Nilai minimum rating
min_rating = min(rating_movies['rating'])

# Nilai maksimal rating
max_rating = max(rating_movies['rating'])

print('Number of User: {}, Number of movies: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movies, min_rating, max_rating
))

# Membuat variabel x untuk mencocokkan data user dan film menjadi satu value
x = rating_movies[['user', 'movie']].values

# Membuat variabel y untuk membuat rating dari hasil
y = rating_movies['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

"""##### **Pembagian Data Pelatihan dan Validasi**"""

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * rating_movies.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""### Modelling

Setelah melakukan Data Preparation, selanjutnya adalah melakukan modelling machine learning. Modelling dalam sistem rekomendasi adalah proses membangun metode yang dapat memberikan rekomendasi berdasarkan preferensi dan kebutuhan pengguna. Dalam kasus ini, sistem rekomendasi yang dibuat menggunakan pendekatan Content-Based Filtering berbasis similarity dan Collaborative Filtering berbasis deep learning

#### **Content-based Filtering**

Pendekatan pertama yang digunakan adalah **Content-Based Filtering**, yaitu metode yang memberikan rekomendasi berdasarkan kesamaan konten antar item. Dalam hal ini, yang digunakan sebagai fitur konten adalah *genres* dari setiap film.

**Langkah-langkah**:
- Data pada kolom `genres` diubah menjadi representasi numerik menggunakan TF-IDF.
- Kemudian dihitung *cosine similarity* antar film berdasarkan TF-IDF tersebut.
- Untuk setiap film yang pernah disukai oleh pengguna, sistem akan merekomendasikan Top-N film lain yang memiliki tingkat kemiripan tertinggi.
"""

def movies_recommendations(judul_film, similarity_data=cosine_sim_df, items=movies_df[['title', 'genres']], k=10):
    """
    Rekomendasi Film berdasarkan kemiripan dataframe

    Parameter:
    ---
    judul_film : tipe data string (str)
                Judul Film (index kemiripan dataframe)
    similarity_data : tipe data pd.DataFrame (object)
                      Kesamaan dataframe, simetrik, dengan judul film sebagai
                      indeks dan kolom
    items : tipe data pd.DataFrame (object)
            Mengandung kedua nama dan fitur lainnya yang digunakan untuk mendefinisikan kemiripan
    k : tipe data integer (int)
        Banyaknya jumlah rekomendasi yang diberikan
    ---


    Pada index ini, kita mengambil k dengan nilai similarity terbesar
    pada index matrix yang diberikan (i).
    """

    if judul_film not in similarity_data.columns:
        raise ValueError(f"Judul film '{judul_film}' tidak ditemukan dalam data.")


    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,judul_film].to_numpy().argpartition(
        range(-1, -k, -1))
    # dengan menggunakan argpartition, kita mengambil sejumlah nilai k tertinggi dari similarity data (dalam kasus ini: dataframe cosine_sim_df)
    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop judul_film agar judul film yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(judul_film, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

"""#### **Collaborative Filtering**

Pendekatan kedua adalah **Collaborative Filtering berbasis Deep Learning**. Metode ini belajar dari interaksi antara pengguna dan item (film) dalam bentuk rating, tanpa melihat konten dari film tersebut. Model ini digunakan untuk memprediksi rating yang mungkin diberikan pengguna terhadap film yang belum pernah ditonton. Dari hasil tersebut diambil **Top-10 film rekomendasi** dengan prediksi rating tertinggi.
"""

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_movies, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_movies = num_movies
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.resto_embedding = layers.Embedding( # layer embeddings resto
        num_movies,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.movies_bias = layers.Embedding(num_movies, 1) # layer embedding resto bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    movies_vector = self.resto_embedding(inputs[:, 1]) # memanggil layer embedding 3
    movies_bias = self.movies_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_movies = tf.tensordot(user_vector, movies_vector, 2)

    x = dot_user_movies + user_bias + movies_bias

    return tf.nn.sigmoid(x) # activation sigmoid

model = RecommenderNet(num_users, num_movies, 50) # inisialisasi model

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

# Memulai training

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 32,
    epochs = 30,
    validation_data = (x_val, y_val)
)

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Dari gambar grafik pelatihan tersebut RMSE dapat diketahui beberapa poin sebagai berikut:
- RMSE data train menurun secara konsisten dari sekitar 0.23 ke sekitar 0.185, menunjukkan bahwa model berhasil belajar dengan baik pada data pelatihan.
- RMSE data test awalnya juga menurun tajam hingga sekitar epoch ke-3 atau ke-4, tetapi kemudian cenderung stagnan dan sedikit fluktuatif di kisaran 0.20.
- Gap antara RMSE train dan test mulai melebar setelah epoch ke-5, yang mengindikasikan adanya kemungkinan overfitting—model terlalu menyesuaikan diri dengan data pelatihan dan kurang generalisasi ke data test.
- Diketahui nilai `RMSE akhir` untuk data `train` sebesar `0.1866`, sedangkan `nilai RMSE` untuk data `validation` sebesar `0.2023`

### **Evaluation**

Pada bagian ini digunakan dua metrik evaluasi untuk menilai kinerja model sistem rekomendasi yang dibangun, yaitu **Root Mean Squared Error (RMSE)** dan **Precision@K**. Kedua metrik ini digunakan untuk mengukur performa model dari sisi regresi dan klasifikasi Top-N rekomendasi. RMSE untuk model Collaborative Filtering, sedangkan Precision@K untuk model Content-based Filtering

#### **Evaluasi Content-based Filtering**
"""

print("Rekomendasi untuk: ")
print(movies_df[movies_df.title == 'Jumanji (1995)'].title[1])
print("genre: ", movies_df[movies_df.title == 'Jumanji (1995)'].genres[1])

# Mendapatkan rekomendasi film yang mirip Jumanji (1995)
movies_recommendations('Jumanji (1995)')

"""Terlihat pada tabel di atas, bahwa Jumlah rekomendasi yang relevan adalah adalah 10. Oleh sebab itu, maka dapat disimpulkan `nilai precision@k untuk model ini adalah 10/10 atau 100%` (hasil dari jumlah rekomendasi yang relevan dibagi dengan total rekomendasi)

#### **Evaluation Collaborative Filtering**
"""

def recommend_movies(user_id):
  movies_watched_by_user = rating_movies[rating_movies.userId == user_id]
  # Operator bitwise (~), bisa diketahui di sini https://docs.python.org/3/reference/expressions.html
  movies_not_watched = movies_df[~movies_df['movieId'].isin(movies_watched_by_user.movieId.values)]['movieId']
  movies_not_watched = list(
      set(movies_not_watched)
      .intersection(set(movie_to_movie_encoded.keys()))
  )

  movies_not_watched = [[movie_to_movie_encoded.get(x)] for x in movies_not_watched]
  user_encoder = user_to_user_encoded.get(user_id)
  user_resto_array = np.hstack(
      ([[user_encoder]] * len(movies_not_watched), movies_not_watched)
  )
  ratings = model.predict(user_resto_array).flatten()

  top_ratings_indices = ratings.argsort()[-10:][::-1]
  recommended_movies_ids = [
      movie_encoded_to_movie.get(movies_not_watched[x][0]) for x in top_ratings_indices
  ]

  print('Showing recommendations for users: {}'.format(user_id))
  print('===' * 9)
  print('Movies with high ratings from user')
  print('----' * 8)

  top_movies_user = (
      movies_watched_by_user.sort_values(
          by = 'rating',
          ascending=False
      )
      .head(5)
      .movieId.values
  )

  movies_df_rows = movies_df[movies_df['movieId'].isin(top_movies_user)]
  for row in movies_df_rows.itertuples():
      print(row.title, ' genre: ', row.genres)

  print('----' * 8)
  print('Top 10 movies recommendation')
  print('----' * 8)

  recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movies_ids)]
  for row in recommended_movies.itertuples():
      print(row.title, ' genre: ', row.genres)

# Mengambil sample user
user_id = rating_movies.userId.sample(1).iloc[0]
recommend_movies(user_id)

"""Dari tabel hasil rekomendasi di atas, dapat disimpulkan bahwa hasil rekomendasi cukup presisi dalam merekomendasikan film untuk userId 318. Terlihat bahwa film yang direkomendasikan setidaknya memiliki satu genre yang mirip dengan film yang diberi rating user. Rata-rata film yang direkomendasikan rilis di bawah tahun 2010, kecuali film Captain Fantastic (2016)."""